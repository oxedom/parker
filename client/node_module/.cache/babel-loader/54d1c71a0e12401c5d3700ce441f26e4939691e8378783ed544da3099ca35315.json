{"ast":null,"code":"\n// import React, { useEffect, useRef, useState } from \"react\";\n// import io from 'socket.io-client';\n\n// const socket = io('http://localhost:2000/')\n\n// const Camera = () => {\n\n//   const [videoOutput, setVideoOutput] = useState()\n//   const getFrame = (videoStream) => {\n//     // create a canvas element to draw the video frame on\n//     const canvas = document.createElement('canvas');\n//     // get the canvas context\n//     const ctx = canvas.getContext('2d');\n//     // set the canvas width and height to match the video dimensions\n//     canvas.width = videoStream.videoWidth;\n//     canvas.height = videoStream.videoHeight;\n\n//     // draw the current video frame onto the canvas\n//     ctx.drawImage(videoStream, 0, 0, canvas.width, canvas.height);\n//     // get the image data from the canvas\n//     const imageData = canvas.toDataURL('image/jpeg');\n\n//     return imageData;\n//   };\n\n//   const inputRef = useRef(null);\n//   const outputRef = useRef(null)\n\n//   const getVideo = () => {\n//     socket.connect()\n//     navigator.mediaDevices\n//       .getUserMedia({ video: { width:  720} })\n//       .then(stream => {\n\n//         let video = inputRef.current;\n//         video.srcObject = stream;\n//         video.play();\n//         // socket.emit('stream', stream);\n\n//         setInterval(() => {\n//           // draw the current video frame onto the canvas\n\n//           // get the image data from the canvas\n//           const result = getFrame(video)\n\n//           // send the image data over the socket connection as a binary string\n//           socket.emit('stream', result );\n//         }, 1000 / 30); // send 30 frames per second\n\n//       })\n//       .catch(err => {\n//         console.error(\"error:\", err);\n//       });\n//     socket.on('output', (data) => {\n\n//       setVideoOutput(data)}) \n//   };\n\n//     useEffect(() => {\n//     getVideo();\n//   }, [inputRef]);\n\n//   useEffect(() => {\n//     let output = outputRef.current\n\n//     const updateOutput = () => {\n//       // console.log(videoOutput)\n//       output.src = test;\n\n//       window.requestAnimationFrame(updateOutput)\n//     }\n//     updateOutput()\n\n//   }, [videoOutput])\n\n//   return (\n//     <div>\n//       <div>\n\n//         <video ref={inputRef} />\n//         <h1> Server </h1>\n//         <video ref={outputRef} /> \n//       </div>\n//     </div>\n//   );\n\n// };\n\n// export default Camera;","map":{"version":3,"names":[],"sources":["/home/sam/projects/parker/client/src/comps/Camera.js"],"sourcesContent":["\n// import React, { useEffect, useRef, useState } from \"react\";\n// import io from 'socket.io-client';\n\n// const socket = io('http://localhost:2000/')\n\n// const Camera = () => {\n\n//   const [videoOutput, setVideoOutput] = useState()\n//   const getFrame = (videoStream) => {\n//     // create a canvas element to draw the video frame on\n//     const canvas = document.createElement('canvas');\n//     // get the canvas context\n//     const ctx = canvas.getContext('2d');\n//     // set the canvas width and height to match the video dimensions\n//     canvas.width = videoStream.videoWidth;\n//     canvas.height = videoStream.videoHeight;\n  \n//     // draw the current video frame onto the canvas\n//     ctx.drawImage(videoStream, 0, 0, canvas.width, canvas.height);\n//     // get the image data from the canvas\n//     const imageData = canvas.toDataURL('image/jpeg');\n  \n//     return imageData;\n//   };\n\n//   const inputRef = useRef(null);\n//   const outputRef = useRef(null)\n\n//   const getVideo = () => {\n//     socket.connect()\n//     navigator.mediaDevices\n//       .getUserMedia({ video: { width:  720} })\n//       .then(stream => {\n        \n//         let video = inputRef.current;\n//         video.srcObject = stream;\n//         video.play();\n//         // socket.emit('stream', stream);\n\n        \n\n\n//         setInterval(() => {\n//           // draw the current video frame onto the canvas\n       \n//           // get the image data from the canvas\n//           const result = getFrame(video)\n     \n//           // send the image data over the socket connection as a binary string\n//           socket.emit('stream', result );\n//         }, 1000 / 30); // send 30 frames per second\n\n\n//       })\n//       .catch(err => {\n//         console.error(\"error:\", err);\n//       });\n//     socket.on('output', (data) => {\n  \n      \n//       setVideoOutput(data)}) \n//   };\n\n//     useEffect(() => {\n//     getVideo();\n//   }, [inputRef]);\n\n//   useEffect(() => {\n//     let output = outputRef.current\n\n//     const updateOutput = () => {\n//       // console.log(videoOutput)\n//       output.src = test;\n      \n//       window.requestAnimationFrame(updateOutput)\n//     }\n//     updateOutput()\n    \n//   }, [videoOutput])\n\n\n\n//   return (\n//     <div>\n//       <div>\n  \n//         <video ref={inputRef} />\n//         <h1> Server </h1>\n//         <video ref={outputRef} /> \n//       </div>\n//     </div>\n//   );\n\n// };\n\n// export default Camera;"],"mappings":";AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAKA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAGA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAIA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA"},"metadata":{},"sourceType":"module","externalDependencies":[]}